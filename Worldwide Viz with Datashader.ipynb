{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plotting Open Flight Data with Datashader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T03:56:43.511580Z",
     "start_time": "2018-10-04T03:56:40.292045Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.utils import export_image\n",
    "from datashader.colors import viridis\n",
    "import dask.dataframe as dd\n",
    "import datetime as dt\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T03:58:33.338964Z",
     "start_time": "2018-10-04T03:58:33.334021Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def spread(pts):\n",
    "    return ((pts[0][1] - pts[0][0]),\n",
    "            (pts[1][1] - pts[1][0]))\n",
    "def ratio(pts):\n",
    "    s = spread(pts)\n",
    "    x, y = s\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-30T19:27:15.795110Z",
     "start_time": "2018-09-30T19:27:15.786784Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "MaxBounds = ((-20048966.10, 20048966.10), (-20026376.39, 20026376.39))\n",
    "WholeWorld = ((-20_037_508, 20_037_508), (-7_670_608, 13_971_466))\n",
    "TwoBounds = ((-20_000_000, 20_000_000), (-20_000_000, 20_000_000))\n",
    "USA_CONUS = ((-13884029, -7453304), (2698291, 6455972))\n",
    "WesternEuro = ((-1181114, 4270391), (3000000, 8081620))\n",
    "Germany = ((709336, 1600000), (6026907, 7270000))\n",
    "Chicago = (( -9828281, -9717659), (5096658, 5161298))\n",
    "Chinatown = (( -9759210, -9754583), (5137122, 5139825))\n",
    "NewYorkCity = (( -8280656, -8175066), (4940514, 4998954))\n",
    "LosAngeles = ((-13195052, -13114944), (3979242, 4023720))\n",
    "Houston = ((-10692703, -10539441), (3432521, 3517616))\n",
    "Austin = ((-10898752, -10855820), (3525750, 3550837))\n",
    "NewOrleans = ((-10059963, -10006348), (3480787, 3510555))\n",
    "Atlanta = ((-9507853,-9274873), (3927030, 4069506))\n",
    "Southeast = ((-10_126_000, -8_903_000), (3_429_000, 4_217_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "parq_file = r'c:\\adsb\\2018_Feb.parq'\n",
    "if not os.path.exists(parq_file):\n",
    "    print('Original data file does not exist. Worldwide plot is not possible.')\n",
    "else:\n",
    "    ddf = dd.read_parquet(parq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2018_Feb.parq-ATL.p.\n",
      "2018_Feb.parq-ATL.p successfully downloaded to D:\\General Stuff\\Software\\Dev\\GitHub\\sfte2018-adsb\\data\\2018_Feb.parq-ATL.p\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "box = Atlanta\n",
    "pickle_name = f'{os.path.basename(parq_file)}-ATL.p'\n",
    "pickle_path = os.path.join(os.getcwd(), 'data', pickle_name)\n",
    "if os.path.exists(pickle_path):\n",
    "    df_atl = pd.read_pickle(pickle_path)\n",
    "else:\n",
    "    from download_files import DownloadFile\n",
    "    if DownloadFile(pickle_path).success:\n",
    "        df_atl = pd.read_pickle(pickle_path)\n",
    "    else:\n",
    "        print('Failed to download file. Reading from original data file.')\n",
    "        if not os.path.exists(parq_file):\n",
    "            print('Original data file does not exist. Atlanta plot is not possible.')\n",
    "        else:\n",
    "            (x1, x2), (y1, y2) = box\n",
    "            df_atl = ddf[(ddf.x > x1) & (ddf.x < x2) & (ddf.y > y1) & (ddf.y < y2)].compute()\n",
    "            df_atl = df_atl.dropna(subset=['x', 'y'], how='any')\n",
    "            df_atl.to_pickle(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "box = USA_CONUS\n",
    "pickle_name = f'{os.path.basename(parq_file)}-CONUS.p'\n",
    "pickle_path = os.path.join(os.getcwd(), 'data', pickle_name)\n",
    "if os.path.exists(pickle_path):\n",
    "    df_usa = pd.read_pickle(pickle_path)\n",
    "else:\n",
    "    try_orig = False\n",
    "    print('Warning: this is a 4.5 Gb file.')\n",
    "    from IPython.core.error import StdinNotImplementedError\n",
    "    try:\n",
    "        cont = input('Do you want to continue downloading? (yes/no) ')\n",
    "    except StdinNotImplementedError:\n",
    "        cont = 'yes'\n",
    "    if cont.lower() == 'yes':\n",
    "        from download_files import DownloadFile\n",
    "        if DownloadFile(pickle_path).success:\n",
    "            df_usa = pd.read_pickle(pickle_path)\n",
    "        else:\n",
    "            print('Failed to download file. Reading from original data file.')\n",
    "            try_orig = True\n",
    "    else:\n",
    "        print('OK. Not downloading file. Reading from original data file.')\n",
    "        try_orig = True\n",
    "    if try_orig:\n",
    "        if not os.path.exists(parq_file):\n",
    "            print('Original data file does not exist. USA plot is not possible.')\n",
    "        else:\n",
    "            (x1, x2), (y1, y2) = box\n",
    "            df_usa = ddf[(ddf.x > x1) & (ddf.x < x2) & (ddf.y > y1) & (ddf.y < y2)].compute()\n",
    "            df_usa = df_usa.dropna(subset=['x', 'y'], how='any')\n",
    "            df_usa.to_pickle(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "box = Southeast\n",
    "pickle_name = f'{os.path.basename(parq_file)}-SE.p'\n",
    "pickle_path = os.path.join(os.getcwd(), 'data', pickle_name)\n",
    "if os.path.exists(pickle_path):\n",
    "    df_se = pd.read_pickle(pickle_path)\n",
    "else:\n",
    "    try_orig = False\n",
    "    print('Warning: this is a 500 Mb file.')\n",
    "    from IPython.core.error import StdinNotImplementedError\n",
    "    try:\n",
    "        cont = input('Do you want to continue downloading? (yes/no) ')\n",
    "    except StdinNotImplementedError:\n",
    "        cont = 'yes'\n",
    "    if cont.lower() == 'yes':\n",
    "        from download_files import DownloadFile\n",
    "        if DownloadFile(pickle_path).success:\n",
    "            df_se = pd.read_pickle(pickle_path)\n",
    "        else:\n",
    "            print('Failed to download file. Reading from original data file.')\n",
    "            try_orig = True\n",
    "    else:\n",
    "        print('OK. Not downloading file. Reading from original data file.')\n",
    "        try_orig = True\n",
    "    if try_orig:\n",
    "        if not os.path.exists(parq_file):\n",
    "            print('Original data file does not exist. Southeast plot is not possible.')\n",
    "        else:\n",
    "            (x1, x2), (y1, y2) = box\n",
    "            df_se = ddf[(ddf.x > x1) & (ddf.x < x2) & (ddf.y > y1) & (ddf.y < y2)].compute()\n",
    "            df_se = df_se.dropna(subset=['x', 'y'], how='any')\n",
    "            df_se.to_pickle(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def create_image(x_range, y_range, plot_width, source=ddf, thresh=None, filename=None, spread=False):\n",
    "    start = dt.datetime.now()\n",
    "    cmap=viridis\n",
    "    r = ratio((x_range, y_range))\n",
    "    plot_height = int(plot_width / r)\n",
    "    cvs = ds.Canvas(plot_width, plot_height, x_range, y_range)\n",
    "    agg = cvs.points(source, 'x', 'y')\n",
    "    print(f'Source contains {len(source):,} rows')\n",
    "    if thresh is not None:\n",
    "        agg = agg.where(agg > thresh)        \n",
    "    img = tf.shade(agg, cmap = cmap)\n",
    "    if spread:\n",
    "        img = tf.dynspread(img, threshold=0.5, max_px=4)\n",
    "    if filename is not None:\n",
    "        export_image(tf.set_background(img, 'black'), filename)\n",
    "    stop = dt.datetime.now()\n",
    "    t = stop - start\n",
    "    print(f\"Image creating time: {t.total_seconds()}s\")\n",
    "    if filename is None:\n",
    "        return tf.set_background(img, 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-30T19:32:41.477224Z",
     "start_time": "2018-09-30T19:30:08.752168Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "create_image(*WholeWorld, 850, thresh=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "create_image(*USA_CONUS, 850, thresh=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "create_image(*Atlanta, 850, source=df_atl, thresh=25, spread=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "create_image(*NewYorkCity, 850, source=df_usa, thresh=20, spread=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fn = \"World-1920-t30.png\"\n",
    "create_image(*WholeWorld, 1920, thresh=30, filename=fn[:-4])\n",
    "display(HTML(f\"\"\"<a href=\"{fn}\" target=\"_blank\">{fn}</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fn = \"USA-1920-t25.png\"\n",
    "create_image(*USA_CONUS, 1920, thresh=25, source=df_usa, filename=fn[:-4])\n",
    "display(HTML(f\"\"\"<a href=\"{fn}\" target=\"_blank\">{fn}</a>\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fn = \"Southeast-1920-t30.png\"\n",
    "create_image(*Southeast, 1920, thresh=30, source=df_se, filename=fn[:-4])\n",
    "display(HTML(f\"\"\"<a href=\"{fn}\" target=\"_blank\">{fn}</a>\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "livereveal": {
   "autolaunch": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
